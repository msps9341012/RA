{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msps9341012/mygym/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from datamanager import DataManager\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamanager = DataManager(\"/home/msps9341012/AGnews\")\n",
    "train_data, dev_data, test_data = datamanager.getdata(4, 70)\n",
    "wv = datamanager.get_wordvector(\"../glove.42B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=5\n",
    "max_lenth=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_l = tf.placeholder(tf.float32, shape=[1, self.dim*2])\n",
    "        input_d = tf.placeholder(tf.float32, shape=[1, self.dim])\n",
    "        \n",
    "        t1 = tflearn.fully_connected(input_l, 1)\n",
    "        t2 = tflearn.fully_connected(input_d, 1)\n",
    "\n",
    "        scaled_out = tflearn.activation(tf.matmul(input_l,t1.W) + tf.matmul(input_d,t2.W) + t1.b, activation = 'sigmoid')\n",
    "        \n",
    "        s_out = tf.clip_by_value(scaled_out[0][0], 1e-5, 1 - 1e-5)\n",
    "\n",
    "        scaled_out = tf.stack([1.0 - s_out, s_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(len(train_data)//batchsize):\n",
    "    datas = train_data[b * batchsize: (b+1) * batchsize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_net:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.state = tf.placeholder(dtype=tf.float32,shape=[None,600], name='state')\n",
    "        self.input_x=tf.placeholder(dtype=tf.float32,shape=[None,300], name='input')\n",
    "        self.reward=tf.placeholder(dtype=tf.float32,shape=[None], name='input')\n",
    "        \n",
    "        with tf.variable_scope('policy_net'):\n",
    "            layer_1 = tf.layers.dense(inputs=self.state, units=1, activation=tf.identity)\n",
    "            layer_2 = tf.layers.dense(inputs=self.input_x, units=1, activation=tf.identity)\n",
    "            self.scaled_out=tf.sigmoid(layer_1+layer_2)\n",
    "            s_out = tf.clip_by_value(self.scaled_out, 1e-5, 1 - 1e-5)\n",
    "            self.scaled_out = tf.concat([1-s_out,s_out],axis=1) # Policy act_prob\n",
    "\n",
    "            self.act_stochastic = tf.multinomial(tf.log(self.scaled_out), num_samples=1) #[batch, n_class]\n",
    "            self.act_stochastic = tf.reshape(self.act_stochastic, shape=[-1])\n",
    "\n",
    "            self.act_deterministic = tf.argmax(self.scaled_out, axis=1)\n",
    "\n",
    "            self.scope = tf.get_variable_scope().name\n",
    "        \n",
    "            \n",
    "            \n",
    "    def act(self,state,x,stochastic=True):\n",
    "        if stochastic:\n",
    "            return tf.get_default_session().run([self.act_stochastic], feed_dict={self.state: state,self.input_x:x})\n",
    "        else:\n",
    "            return tf.get_default_session().run([self.act_deterministic], feed_dict={self.state: state,self.input_x:x})\n",
    "\n",
    "    #def get_action_prob(self, obs):\n",
    "        #return tf.get_default_session().run(self.act_probs, feed_dict={self.obs: obs})\n",
    "\n",
    "    def get_variables(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.scope)\n",
    "\n",
    "    def get_trainable_variables(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'policy_net/ArgMax:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.act_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Policy_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_critic_network(self, Scope): #取得reward\n",
    "        inputs = tf.placeholder(shape=[1, self.max_lenth], dtype=tf.int32, name=\"inputs\")\n",
    "        lenth = tf.placeholder(shape=[1], dtype=tf.int32, name=\"lenth\")\n",
    "       \n",
    "        #Lower network\n",
    "        if Scope[-1] == 'e':\n",
    "            vec = tf.nn.embedding_lookup(self.wordvector, inputs)\n",
    "        else:\n",
    "            vec = tf.nn.embedding_lookup(self.target_wordvector, inputs)\n",
    "        cell = LSTMCell(self.dim, initializer=self.init, state_is_tuple=False)\n",
    "        \n",
    "        with tf.variable_scope(\"Lower\", reuse=True):\n",
    "            out, _ = tf.nn.dynamic_rnn(cell, vec, lenth, dtype=tf.float32, scope=Scope)\n",
    "        out = tf.gather(out[0], lenth-1) #取出最後一個\n",
    "        \n",
    "        out = tflearn.dropout(out, self.keep_prob)\n",
    "        out = tflearn.fully_connected(out, self.grained, scope=Scope+\"/pred\", name=\"get_pred\")\n",
    "        return inputs, lenth, out\n",
    "    \n",
    "    def create_LSTM_cell(self,Scope):\n",
    "        cell = LSTMCell(self.dim, initializer=self.init, state_is_tuple=False)\n",
    "        state = tf.placeholder(tf.float32, shape = [1, cell.state_size], name=\"cell_state\")\n",
    "        inputs = tf.placeholder(tf.int32, shape = [1, 1], name=\"cell_input\")\n",
    "        if Scope[-1] == 'e':\n",
    "            vec = tf.nn.embedding_lookup(self.wordvector, inputs)\n",
    "        else:\n",
    "            vec = tf.nn.embedding_lookup(self.target_wordvector, inputs)\n",
    "        with tf.variable_scope(Scope, reuse=False):\n",
    "            out, state1 = cell(vec[:,0,:], state)\n",
    "        return state, inputs, out, state1\n",
    "    \n",
    "    def create_wordvector_find(self):\n",
    "        inputs = tf.placeholder(tf.int32, shape=[1, self.max_lenth], name=\"WVtofind\")\n",
    "        vec = tf.nn.embedding_lookup(self.target_wordvector, inputs)\n",
    "        return inputs, vec\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CriticNetwork(self):\n",
    "    def __init__(self, tau, wordvector):\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32, name=\"keepprob\")\n",
    "        self.seq = tf.placeholder(shape=[1, 70], dtype=tf.int32, name=\"input_seq\") #70 for max length 一條\n",
    "        \n",
    "        self.cell_state=tf.placeholder(tf.float32, shape = [1, 600], name=\"cell_state\")\n",
    "        self.cell_input=tf.placeholder(tf.int32, shape = [1, 1], name=\"cell_input\")\n",
    "        \n",
    "        self.lenth = tf.placeholder(shape=[1], dtype=tf.int32, name=\"lenth\")\n",
    "        self.wordvector = tf.get_variable('wordvector', dtype=tf.float32, initializer=wordvector, trainable=True)\n",
    "        \n",
    "        self.ground_truth = tf.placeholder(tf.float32, [1,4], name=\"ground_truth\")\n",
    "        self.init = tf.random_uniform_initializer(-0.05, 0.05, dtype=tf.float32)\n",
    "        \n",
    "        seq_vec = tf.nn.embedding_lookup(self.wordvector, self.seq)\n",
    "        \n",
    "        vec = tf.nn.embedding_lookup(self.wordvector, self.cell_input) #for one step\n",
    "\n",
    "        with tf.variable_scope('Critic'):\n",
    "            with tf.variable_scope('Rep'):\n",
    "                self.cell = LSTMCell(300, initializer=self.init, state_is_tuple=False)\n",
    "                output, state=tf.nn.dynamic_rnn(self.cell,seq_vec,dtype=tf.float32,sequence_length=self.lenth)\n",
    "                output = tf.gather(output[0], self.lenth-1) #取出最後一個\n",
    "                scope.reuse_variables()\n",
    "                \n",
    "            with tf.variable_scope('CNet'):\n",
    "                self.layer1 = tf.layers.dropout(output, self.keep_prob)   # drop out 50% of inputs\n",
    "                self.target_out = tf.layers.dense(self.layer1, 4) #output: 4\n",
    "                \n",
    "            #one step            \n",
    "            self.output_next, self.h_next = self.cell.call(vec[:,0,:], self.cell_state)\n",
    "            \n",
    "        self.prob=tf.nn.softmax(target_out)\n",
    "        self.loss_target = tf.nn.softmax_cross_entropy_with_logits(labels=self.ground_truth, logits=self.target_out)\n",
    "    \n",
    "    def get_next_state(self,x,init_h):\n",
    "        return tf.get_default_session().run([self.output_next,self.h_next], feed_dict={self.cell_input: x,\n",
    "                                                                                      self.cell_state:init_h})\n",
    "    def get_reward(self,sequence,label):\n",
    "        return tf.get_default_session().run([self.prob], feed_dict={self.seq: sequence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_net:\n",
    "    def __init__(self, name: str, env, temp=0.1):\n",
    "        \"\"\"\n",
    "        :param name: string\n",
    "        :param temp: temperature of boltzmann distribution\n",
    "        \"\"\"\n",
    "        #self.rate=tf.placeholder(dtype=tf.float32,shape=())\n",
    "        with tf.variable_scope(name):\n",
    "            self.sequence = tf.placeholder(tf.float32, [1,250, 10])\n",
    "            self.actual_legnth=tf.sign(tf.reduce_max(tf.abs(self.sequence), 2))\n",
    "            layer=[36,24]\n",
    "            #layer=[256]\n",
    "            with tf.variable_scope('out') as scope:\n",
    "\n",
    "                self.weights = {\n",
    "                    'h_r': tf.get_variable('h_r',[24, 3], initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")),\n",
    "                    'h_v': tf.get_variable('h_v',[24, 1], initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\"))}\n",
    "                self.biases = {\n",
    "                    'b_r': tf.get_variable('b_r',[3], initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")),\n",
    "                    'b_v': tf.get_variable('b_v',[1], initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\"))\n",
    "                }\n",
    "                scope.reuse_variables()\n",
    "                \n",
    "            with tf.variable_scope('rnn',initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")):\n",
    "                #BasicRNNCell\n",
    "                self.cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(num_units=i) for i in layer])\n",
    "                self.h0=self.cell.zero_state(1, dtype=tf.float32)\n",
    "                output, state=tf.nn.dynamic_rnn(self.cell,self.sequence,dtype=tf.float32,sequence_length=length(self.sequence),initial_state=self.h0)\n",
    "                scope.reuse_variables()\n",
    "            with tf.variable_scope('vrnn',initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")):\n",
    "                self.vcell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(num_units=i) for i in layer])\n",
    "                self.v0=self.vcell.zero_state(1, dtype=tf.float32)\n",
    "                output_v, state_v = tf.nn.dynamic_rnn(self.vcell,self.sequence,dtype=tf.float32,sequence_length=length(self.sequence),initial_state=self.v0)\n",
    "                scope.reuse_variables()\n",
    "                \n",
    "            #self.rnn=RNN(env)\n",
    "            self.obs = tf.placeholder(dtype=tf.float32,shape=[1] + list(env.observation_space), name='obs')\n",
    "\n",
    "            self.scope = tf.get_variable_scope().name\n",
    "\n",
    "        act_probs=tf.nn.softmax(tf.add(tf.matmul(tf.reshape(output,[250,24]),self.weights['h_r']), self.biases['b_r']))\n",
    "        self.act_probs_all=tf.multiply(act_probs,tf.transpose(self.actual_legnth,[1,0]))\n",
    "        v_preds=tf.add(tf.matmul(tf.reshape(output_v,[250,24]), self.weights['h_v']), self.biases['b_v'])\n",
    "        self.v_preds_all=tf.multiply(v_preds,tf.transpose(self.actual_legnth,[1,0]))\n",
    "        \n",
    "        #one step\n",
    "        self.output_1, self.h1 = self.cell.call(self.obs, self.h0)\n",
    "        act_prob=tf.nn.softmax(tf.add(tf.matmul(self.output_1, self.weights['h_r']), self.biases['b_r']))\n",
    "        \n",
    "        self.output_v1, self.vh1 = self.vcell.call(self.obs,self.v0)\n",
    "        self.v_pred=tf.add(tf.matmul(self.output_v1, self.weights['h_v']), self.biases['b_v'])\n",
    "        \n",
    "        self.act_stochastic = tf.multinomial(tf.log(act_prob), num_samples=1)\n",
    "        self.act_stochastic = tf.reshape(self.act_stochastic, shape=[-1])\n",
    "        self.act_deterministic = tf.argmax(act_probs, axis=1)\n",
    "        \n",
    "    def get_next_state(self,state,init_h,init_v,stochastic=True):\n",
    "            return tf.get_default_session().run([self.act_stochastic, self.v_pred,self.h1,self.vh1], \n",
    "                                                feed_dict={self.obs: obs,self.h0:init_h,self.v0:init_v})\n",
    "        else:\n",
    "            return tf.get_default_session().run([self.act_stochastic, self.v_pred,self.h1,self.vh1], \n",
    "                                                feed_dict={self.obs: obs,self.h0:init_h,self.v0:init_v})\n",
    "    def get_variables(self):\n",
    "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.scope)\n",
    "\n",
    "    def get_trainable_variables(self):\n",
    "        return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.scope)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
